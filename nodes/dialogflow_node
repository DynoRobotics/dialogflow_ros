#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# License: BSD
#   https://raw.githubusercontent.com/samiamlabs/dyno/master/LICENCE
#

import rospy
import uuid
import dialogflow_v2 as dialogflow

import std_msgs.msg as std_msgs
from audio_common_msgs.msg import AudioData
from dialogflow_ros.msg import DialogflowResponse

from std_srvs.srv import Empty, EmptyResponse

from collections import deque
from google.oauth2 import service_account


class DialogflowNode:
    def __init__(self):
        rospy.init_node('dialogflow_node')

        if not rospy.has_param('~google_application_credentials'):
            rospy.logerr("Missing path to credentials file")
            raise ValueError('Missing path to credentials file')

        google_application_credentials = rospy.get_param('~google_application_credentials')
        self.credentials = service_account.Credentials.from_service_account_file(google_application_credentials)

        self.project_id = self.credentials.project_id
        self.session_id = rospy.get_param('~session_id', uuid.uuid4())
        self.default_language = rospy.get_param('~default_language', 'en-US')
        self.disable_audio = rospy.get_param('~disable_audio', False)

        self.session_client = dialogflow.SessionsClient(credentials=self.credentials)
        self.session = self.session_client.session_path(self.project_id, self.session_id)
        rospy.loginfo('Session path: {}\n'.format(self.session))

        self.audio_chunk_queue = deque()
        self.max_queue_size = 100

        # Note: hard coding audio_encoding and sample_rate_hertz for simplicity.
        audio_encoding = dialogflow.enums.AudioEncoding.AUDIO_ENCODING_LINEAR_16
        sample_rate_hertz = 16000
        self.audio_config = dialogflow.types.InputAudioConfig(
            audio_encoding=audio_encoding, language_code=self.default_language,
            sample_rate_hertz=sample_rate_hertz)

        self.query_result_pub = rospy.Publisher('response', DialogflowResponse, queue_size=10)
        self.query_text_pub = rospy.Publisher('query_text', std_msgs.String, queue_size=10)

        rospy.Subscriber('/text', std_msgs.String, self.text_callback)

        if not self.disable_audio:
            rospy.Subscriber('/audio', AudioData, self.audio_callback)

        self.list_intents_sevice = rospy.Service(
                'list_intents',
                Empty,
                self.handle_list_intents)

        self.list_context_sevice = rospy.Service(
                'list_context',
                Empty,
                self.handle_list_context)

        self.list_context_sevice = rospy.Service(
                'clear_context',
                Empty,
                self.handle_clear_context)

    def handle_list_intents(self, request):
        intents_client = dialogflow.IntentsClient(credentials=self.credentials)
        parent = intents_client.project_agent_path(self.project_id)
        intents = intents_client.list_intents(parent)

        for intent in intents:
            rospy.loginfo('=' * 20)
            rospy.loginfo('Intent name: {}'.format(intent.name.encode('utf-8')))
            rospy.loginfo('Intent display_name: {}'.format(intent.display_name.encode('utf-8')))
            rospy.loginfo('Action: {}\n'.format(intent.action.encode('utf-8')))
            rospy.loginfo('Root followup intent: {}'.format(
                intent.root_followup_intent_name.encode('utf-8')))
            rospy.loginfo('Parent followup intent: {}\n'.format(
                intent.parent_followup_intent_name.encode('utf-8')))

            rospy.loginfo('Input contexts:')
            for input_context_name in intent.input_context_names:
                rospy.loginfo('\tName: {}'.format(input_context_name.encode('utf-8')))

            rospy.loginfo('Output contexts:')
            for output_context in intent.output_contexts:
                rospy.loginfo('\tName: {}'.format(output_context.name.encode('utf-8')))
        return EmptyResponse()

    def handle_list_context(self, request):
        contexts_client = dialogflow.ContextsClient(credentials=self.credentials)
        contexts = contexts_client.list_contexts(self.session)

        rospy.loginfo('Contexts for session {}:\n'.format(self.session))
        for context in contexts:
            rospy.loginfo('Context name: {}'.format(context.name))
            rospy.loginfo('Lifespan count: {}'.format(context.lifespan_count))
            rospy.loginfo('Fields:')
            for field, value in context.parameters.fields.items():
                if value.string_value:
                    rospy.loginfo('\t{}: {}'.format(field, value))
        return EmptyResponse()

    def handle_clear_context(self, request):
        contexts_client = dialogflow.ContextsClient(credentials=self.credentials)
        contexts = contexts_client.list_contexts(self.session)
        for context in contexts:
            contexts_client.delete_context(context.name)
        return EmptyResponse()


    def text_callback(self, text_msg):
        self.query_text_pub.publish(text_msg)
        query_result = self.detect_intent_text(text_msg.data)
        self.publish_response(query_result)

    def publish_response(self, query_result):
        query_result_msg = DialogflowResponse()
        query_result_msg.project_id = self.project_id
        query_result_msg.transcript = query_result.query_text.encode('utf-8') # text_msg.data
        query_result_msg.intent_detection_confidence = query_result.intent_detection_confidence
        query_result_msg.intent = query_result.intent

        if not query_result.fulfillment_text:
            fulfillment_messages = query_result.fulfillment_messages
            if len(fulfillment_messages) > 0:
                query_result_msg.fulfillment_text = fulfillment_messages[0].text.text[0].encode('utf-8')
            else:
                rospy.logwarn("No fulfillment_text can be parsed")
        else:
            query_result_msg.fulfillment_text = str(query_result.fulfillment_text.encode('utf-8'))

        self.query_result_pub.publish(query_result_msg)

    def audio_callback(self, audio_chunk_msg):
        if len(self.audio_chunk_queue) < self.max_queue_size:
            self.audio_chunk_queue.append(audio_chunk_msg.data)
        else:
            rospy.logwarn("Audio chunk queue if full, clearing!")
            self.audio_chunk_queue = deque()

    def detect_intent_text(self, text):

        text_input = dialogflow.types.TextInput(text=text, language_code=self.default_language)
        query_input = dialogflow.types.QueryInput(text=text_input)
        response = self.session_client.detect_intent(session=self.session, query_input=query_input)

        rospy.loginfo(response)

        rospy.loginfo('=' * 20)
        rospy.loginfo('Query text: {}'.format(response.query_result.query_text.encode('utf-8')))
        rospy.loginfo('Detected intent: {} (confidence: {})\n'.format(
            response.query_result.intent.display_name.encode('utf-8'),
            response.query_result.intent_detection_confidence))
        rospy.loginfo('Fulfillment text: {}\n'.format(
            response.query_result.fulfillment_text.encode('utf-8')))
        return response.query_result

    def detect_intent_stream(self):
        requests = self.audio_stream_request_generator()
        responses = self.session_client.streaming_detect_intent(requests)

        rospy.loginfo('=' * 20)
        try:
            for response in responses:
                rospy.loginfo('Intermediate transcript: "{}".'.format(
                        response.recognition_result.transcript.encode('utf-8')))
        except:
            rospy.logerr("Dialogflow exception, out of audio quota?")
            return

        # Note: The result from the last response is the final transcript along
        # with the detected content.
        query_result = response.query_result

        if query_result.query_text == "":
            return

        self.query_text_pub.publish(std_msgs.String(data=query_result.query_text.encode('utf-8')))

        rospy.loginfo('=' * 20)
        rospy.loginfo('Query text: {}'.format(query_result.query_text.encode('utf-8')))
        rospy.loginfo('Detected intent: {} (confidence: {})\n'.format(
            query_result.intent.display_name.encode('utf-8'),
            query_result.intent_detection_confidence))
        rospy.loginfo('Fulfillment text: {}\n'.format(
            query_result.fulfillment_text.encode('utf-8')))

        self.publish_response(query_result)

    def audio_stream_request_generator(self):
        query_input = dialogflow.types.QueryInput(audio_config=self.audio_config)

        # The first request contains the configuration.
        yield dialogflow.types.StreamingDetectIntentRequest(
            session=self.session,
            query_input=query_input,
            single_utterance=True)

        # Here we are reading small chunks of audio from a dequeue
        while True:
            # Wait for more chunks to allow continious streaming
            if len(self.audio_chunk_queue) == 0:
                rospy.sleep(0.1)
                if len(self.audio_chunk_queue) == 0:
                    break

            chunk = self.audio_chunk_queue.popleft()

            # The later requests contains audio data.
            yield dialogflow.types.StreamingDetectIntentRequest(input_audio=chunk)

    def update(self):
        if len(self.audio_chunk_queue) > 0:
            self.detect_intent_stream()
            # TODO: Publish query_reslut


if __name__ == '__main__':
    dialogflow_node = DialogflowNode()
    while not rospy.is_shutdown():
        dialogflow_node.update()
        rospy.sleep(0.1)
